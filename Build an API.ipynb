{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an API for machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In real case, we need to deploy our model into production.\n",
    "There are two methods to do so, batch and with API.\n",
    "Today, we will discuss about create API to provide real time prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build API which contains a model for classifying iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data into dataframe\n",
    "trainFile = \"dataset/iris.data\"\n",
    "train = pd.read_csv(trainFile, delimiter=',', names=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\",\"class\"])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define feature, excluding 'class' column\n",
    "features = [feature for feature in train.columns if feature not in ['class']]\n",
    "print('Total features : {}'.format(len(features)))\n",
    "\n",
    "#label\n",
    "label = train['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test split - 70% training, 30% testing\n",
    "seed = 1987\n",
    "\n",
    "train_data, test_data, train_label, test_label = train_test_split(train[features], label, test_size = 0.3, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a model\n",
    "model = RandomForestClassifier(random_state = seed).fit(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train score \n",
    "model.score(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test score\n",
    "model.score(test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the prediction and the ground truth on test data\n",
    "test_data['prediction'] = model.predict(test_data)\n",
    "test_data['ground truth'] = test_label\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After that, what should we do?\n",
    "Mostly, online courses teach machine learning stop the lecture and materials up until evaluating, and continue to optimize the accuracy. This creates confusion for new Data Scientists that Machine Learning is \"an art of optimizing score of Testing dataset in Notebook environment\". In fact, machine learning should be part of a system, a code or application so that it will impact customer experience and increase business value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a pickle file for storing the model.\n",
    "Pickle is usually used for saving the data on our disk, so next time we could call it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model as a file\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pickle for the model\n",
    "joblib.dump(model, 'ml_model/model_rf_iris.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the next step, after getting the pickle file?\n",
    "Usually, this file will be copied to other code based outside of this notebook. But for this tutorial, we will use the same notebook , but pretend that anything below this line is in a different environment. \n",
    "\n",
    "Notes: To make sure anything written below is independent from any variable above, you can restart the Kernel, and start running below codes, without run above codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of Production ML\n",
    "\n",
    "There are two types of machine learning production: Batch and serve as API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Batch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Its most common the code not in Notebook format, so it should be like this in a .py file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Extract\n",
    "# This lines could be codes that extract or load data from any database directly\n",
    "file = \"dataset/iris_new_data.data\"\n",
    "new_data = pd.read_csv(file, delimiter = ',', names = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"])\n",
    "\n",
    "#Transform\n",
    "rf_model_load = joblib.load('ml_model/model_rf_iris.pkl')\n",
    "new_data['prediction'] = rf_model_load.predict(new_data)\n",
    "\n",
    "#Load\n",
    "# This lines could be codes that Export data to any database directly\n",
    "new_data.to_csv(\"predicted_iris_data.csv\", sep=',',index=False)\n",
    "\n",
    "print(\"Job Success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Batch \n",
    "\n",
    "Above codes can be scheduled using server scheduler, or have User interface to trigger the ETL job. Extract and Load part of code can be called from any data sources to any data source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Serve as API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to build an API, we will utilize Flask.\n",
    "\n",
    "Flask is commonly employed for building web application. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install the library\n",
    "!pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define flask\n",
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a decorator to define the path of url and method\n",
    "@app.route('/predict_ml', methods = ['POST'])\n",
    "\n",
    "#function and the decorator will be mapped based on the method\n",
    "def predict():\n",
    "    if request.method == 'POST':\n",
    "        #request data and store it in json format\n",
    "        data = sepal.data\n",
    "        dataDict = json.loads(data)\n",
    "        \n",
    "        #convert the json format to dataframe, load the model and predict it\n",
    "        pandas_df = pd.DataFrame([dataDict])\n",
    "        rf_model_load = joblib.load('ml_model/model_rf_iris.pkl')\n",
    "        prediction = rf_model_load.predict(pandas_df)[0]\n",
    "        print(prediction)\n",
    "        \n",
    "        #result whenever someone called the API\n",
    "        return jsonify({'prediction': prediction})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start below lines to start the web application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes that below code is a running service, means that it will never finish as a process. It will always run until you decide to stop the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "     app.run(host = 'localhost',port = 8080)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input the testing data into API\n",
    "\n",
    "Open postman or can be downloaded as extension in Chrome, then type the input and don't forget to use POST method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format input to API\n",
    "{\n",
    "    \"sepal_length\": 5.3,\n",
    "    \"sepal_width\": 2.4,\n",
    "    \"petal_length\": 2.5,\n",
    "    \"petal_width\": 4.2\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In Practice\n",
    "It's not a common practice to start a serving application in Jupyter Notebook!\n",
    "Usually the above codes will be run in a web server written in a .py code like below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from flask import Flask, jsonify,request,session\n",
    "from sklearn.externals import joblib\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import os.path\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/predict_ml', methods=['POST'])\n",
    "def predict_ml():\n",
    "    if request.method=='POST':\n",
    "        data = request.data\n",
    "        dataDict = json.loads(data)\n",
    "        \n",
    "        pandas_df = pd.DataFrame([dataDict])\n",
    "        rf_model_load = joblib.load('ml_model/model_rf_iris.pkl')\n",
    "        prediction = rf_model_load.predict(pandas_df)[0]\n",
    "        print(prediction)\n",
    "        \n",
    "        return jsonify({'prediction': prediction})\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "     app.run(host='localhost',port=8080)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is that really?\n",
    "Well, up to this point, this is Software Engineer area. It's common for a Software Engineer to use REST API like above.\n",
    "For example, you can call the link in a REST API Client, looks like below. This shows your model url linked being called, and has 4 inputs variable. When the request made, the response shows the prediction result. \n",
    "![alt text](ML Model in Production/screenshot call API.jpg \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "Machine Learning is not only \"An art of increasing accuracy in a notebook\", it is a part of software engineering\n",
    "There are 2 common methods to use Machine Learning model in production Batch and REST API\n",
    "Hope this tutorial helping you"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
